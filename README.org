Home AI server

Goals:
- Easy-to-use, fully featured AI chat interface
- Access to one or more frontier models
- Multi-user
- Accessible on LAN only
- Pay as you go for all LLM interactions
- Installable on mobile as a progressive web app

Implementation:
- open-webui running in docker-compose
- Backed by AWS Bedrock foundation models and local ollama
- bedrock-access-gateway to access Bedrock chat models
- litellm API adapter to access a Bedrock embedding model
- nginx SSL termination with self-signed cert

TODO
- [ ] Move deploy script to a CloudFormation stack
- [ ] Mount open-webui config.json
- [ ] Move secrets volumes to docker compose secrets
- [ ] Create backup strategy
- [ ] Set up auto-update
- [X] Document/automate checking out bedrock-access-gateway
- [X] Prefix AWS environment variables in .env


* Setup

When cloning this repo, you'll need to pull submodules to get Bedrock Access Gateway:

#+begin_src sh
git clone --recurse-submodules
#+end_src
